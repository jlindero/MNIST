{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_LeNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oHbHSk44L-KC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23d2d866-6bbb-4e27-c134-d0999222076a"
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import datasets\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQ4ZBxEkL_ZF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class ShallowNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\"\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\n",
        "\t\t# define the first (and only) CONV => RELU layer\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LR9GoKO9MUAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\n",
        "\t\t# first set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\t\t# second set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(500))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97UscY2dShtI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "\tdef __init__(self, layers, alpha=0.1):\n",
        "\t\t# initialize the list of weights matrices, then store the\n",
        "\t\t# network architecture and learning rate\n",
        "\t\tself.W = []\n",
        "\t\tself.layers = layers\n",
        "\t\tself.alpha = alpha\n",
        "\n",
        "\t\t# start looping from the index of the first layer but\n",
        "\t\t# stop before we reach the last two layers\n",
        "\t\tfor i in np.arange(0, len(layers) - 2):\n",
        "\t\t\t# randomly initialize a weight matrix connecting the\n",
        "\t\t\t# number of nodes in each respective layer together,\n",
        "\t\t\t# adding an extra node for the bias\n",
        "\t\t\tw = np.random.randn(layers[i] + 1, layers[i + 1] + 1)\n",
        "\t\t\tself.W.append(w / np.sqrt(layers[i]))\n",
        "\n",
        "\t\t# the last two layers are a special case where the input\n",
        "\t\t# connections need a bias term but the output does not\n",
        "\t\tw = np.random.randn(layers[-2] + 1, layers[-1])\n",
        "\t\tself.W.append(w / np.sqrt(layers[-2]))\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\t# construct and return a string that represents the network\n",
        "\t\t# architecture\n",
        "\t\treturn \"NeuralNetwork: {}\".format(\n",
        "\t\t\t\"-\".join(str(l) for l in self.layers))\n",
        "\n",
        "\tdef sigmoid(self, x):\n",
        "\t\t# compute and return the sigmoid activation value for a\n",
        "\t\t# given input value\n",
        "\t\treturn 1.0 / (1 + np.exp(-x))\n",
        "\n",
        "\tdef sigmoid_deriv(self, x):\n",
        "\t\t# compute the derivative of the sigmoid function ASSUMING\n",
        "\t\t# that `x` has already been passed through the `sigmoid`\n",
        "\t\t# function\n",
        "\t\treturn x * (1 - x)\n",
        "\n",
        "\tdef fit(self, X, y, epochs=1000, displayUpdate=100):\n",
        "\t\t# insert a column of 1's as the last entry in the feature\n",
        "\t\t# matrix -- this little trick allows us to treat the bias\n",
        "\t\t# as a trainable parameter within the weight matrix\n",
        "\t\tX = np.c_[X, np.ones((X.shape[0]))]\n",
        "\n",
        "\t\t# loop over the desired number of epochs\n",
        "\t\tfor epoch in np.arange(0, epochs):\n",
        "\t\t\t# loop over each individual data point and train\n",
        "\t\t\t# our network on it\n",
        "\t\t\tfor (x, target) in zip(X, y):\n",
        "\t\t\t\tself.fit_partial(x, target)\n",
        "\n",
        "\t\t\t# check to see if we should display a training update\n",
        "\t\t\tif epoch == 0 or (epoch + 1) % displayUpdate == 0:\n",
        "\t\t\t\tloss = self.calculate_loss(X, y)\n",
        "\t\t\t\tprint(\"[INFO] epoch={}, loss={:.7f}\".format(\n",
        "\t\t\t\t\tepoch + 1, loss))\n",
        "\n",
        "\tdef fit_partial(self, x, y):\n",
        "\t\t# construct our list of output activations for each layer\n",
        "\t\t# as our data point flows through the network; the first\n",
        "\t\t# activation is a special case -- it's just the input\n",
        "\t\t# feature vector itself\n",
        "\t\tA = [np.atleast_2d(x)]\n",
        "\n",
        "\t\t# FEEDFORWARD:\n",
        "\t\t# loop over the layers in the network\n",
        "\t\tfor layer in np.arange(0, len(self.W)):\n",
        "\t\t\t# feedforward the activation at the current layer by\n",
        "\t\t\t# taking the dot product between the activation and\n",
        "\t\t\t# the weight matrix -- this is called the \"net input\"\n",
        "\t\t\t# to the current layer\n",
        "\t\t\tnet = A[layer].dot(self.W[layer])\n",
        "\n",
        "\t\t\t# computing the \"net output\" is simply applying our\n",
        "\t\t\t# non-linear activation function to the net input\n",
        "\t\t\tout = self.sigmoid(net)\n",
        "\n",
        "\t\t\t# once we have the net output, add it to our list of\n",
        "\t\t\t# activations\n",
        "\t\t\tA.append(out)\n",
        "\n",
        "\t\t# BACKPROPAGATION\n",
        "\t\t# the first phase of backpropagation is to compute the\n",
        "\t\t# difference between our *prediction* (the final output\n",
        "\t\t# activation in the activations list) and the true target\n",
        "\t\t# value\n",
        "\t\terror = A[-1] - y\n",
        "\n",
        "\t\t# from here, we need to apply the chain rule and build our\n",
        "\t\t# list of deltas `D`; the first entry in the deltas is\n",
        "\t\t# simply the error of the output layer times the derivative\n",
        "\t\t# of our activation function for the output value\n",
        "\t\tD = [error * self.sigmoid_deriv(A[-1])]\n",
        "\n",
        "\t\t# once you understand the chain rule it becomes super easy\n",
        "\t\t# to implement with a `for` loop -- simply loop over the\n",
        "\t\t# layers in reverse order (ignoring the last two since we\n",
        "\t\t# already have taken them into account)\n",
        "\t\tfor layer in np.arange(len(A) - 2, 0, -1):\n",
        "\t\t\t# the delta for the current layer is equal to the delta\n",
        "\t\t\t# of the *previous layer* dotted with the weight matrix\n",
        "\t\t\t# of the current layer, followed by multiplying the delta\n",
        "\t\t\t# by the derivative of the non-linear activation function\n",
        "\t\t\t# for the activations of the current layer\n",
        "\t\t\tdelta = D[-1].dot(self.W[layer].T)\n",
        "\t\t\tdelta = delta * self.sigmoid_deriv(A[layer])\n",
        "\t\t\tD.append(delta)\n",
        "\n",
        "\t\t# since we looped over our layers in reverse order we need to\n",
        "\t\t# reverse the deltas\n",
        "\t\tD = D[::-1]\n",
        "\n",
        "\t\t# WEIGHT UPDATE PHASE\n",
        "\t\t# loop over the layers\n",
        "\t\tfor layer in np.arange(0, len(self.W)):\n",
        "\t\t\t# update our weights by taking the dot product of the layer\n",
        "\t\t\t# activations with their respective deltas, then multiplying\n",
        "\t\t\t# this value by some small learning rate and adding to our\n",
        "\t\t\t# weight matrix -- this is where the actual \"learning\" takes\n",
        "\t\t\t# place\n",
        "\t\t\tself.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n",
        "\n",
        "\tdef predict(self, X, addBias=True):\n",
        "\t\t# initialize the output prediction as the input features -- this\n",
        "\t\t# value will be (forward) propagated through the network to\n",
        "\t\t# obtain the final prediction\n",
        "\t\tp = np.atleast_2d(X)\n",
        "\n",
        "\t\t# check to see if the bias column should be added\n",
        "\t\tif addBias:\n",
        "\t\t\t# insert a column of 1's as the last entry in the feature\n",
        "\t\t\t# matrix (bias)\n",
        "\t\t\tp = np.c_[p, np.ones((p.shape[0]))]\n",
        "\n",
        "\t\t# loop over our layers in the network\n",
        "\t\tfor layer in np.arange(0, len(self.W)):\n",
        "\t\t\t# computing the output prediction is as simple as taking\n",
        "\t\t\t# the dot product between the current activation value `p`\n",
        "\t\t\t# and the weight matrix associated with the current layer,\n",
        "\t\t\t# then passing this value through a non-linear activation\n",
        "\t\t\t# function\n",
        "\t\t\tp = self.sigmoid(np.dot(p, self.W[layer]))\n",
        "\n",
        "\t\t# return the predicted value\n",
        "\t\treturn p\n",
        "\n",
        "\tdef calculate_loss(self, X, targets):\n",
        "\t\t# make predictions for the input data points then compute\n",
        "\t\t# the loss\n",
        "\t\ttargets = np.atleast_2d(targets)\n",
        "\t\tpredictions = self.predict(X, addBias=False)\n",
        "\t\tloss = 0.5 * np.sum((predictions - targets) ** 2)\n",
        "\n",
        "\t\t# return the loss\n",
        "\t\treturn loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-QOAT-pSvCM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "\tdef __init__(self, N, alpha=0.1):\n",
        "\t\t# initialize the weight matrix and store the learning rate\n",
        "\t\tself.W = np.random.randn(N + 1) / np.sqrt(N)\n",
        "\t\tself.alpha = alpha\n",
        "\n",
        "\tdef step(self, x):\n",
        "\t\t# apply the step function\n",
        "\t\treturn 1 if x > 0 else 0\n",
        "\n",
        "\tdef fit(self, X, y, epochs=10):\n",
        "\t\t# insert a column of 1's as the last entry in the feature\n",
        "\t\t# matrix -- this little trick allows us to treat the bias\n",
        "\t\t# as a trainable parameter within the weight matrix\n",
        "\t\tX = np.c_[X, np.ones((X.shape[0]))]\n",
        "\n",
        "\t\t# loop over the desired number of epochs\n",
        "\t\tfor epoch in np.arange(0, epochs):\n",
        "\t\t\t# loop over each individual data point\n",
        "\t\t\tfor (x, target) in zip(X, y):\n",
        "\t\t\t\t# take the dot product between the input features\n",
        "\t\t\t\t# and the weight matrix, then pass this value\n",
        "\t\t\t\t# through the step function to obtain the prediction\n",
        "\t\t\t\tp = self.step(np.dot(x, self.W))\n",
        "\n",
        "\t\t\t\t# only perform a weight update if our prediction\n",
        "\t\t\t\t# does not match the target\n",
        "\t\t\t\tif p != target:\n",
        "\t\t\t\t\t# determine the error\n",
        "\t\t\t\t\terror = p - target\n",
        "\n",
        "\t\t\t\t\t# update the weight matrix\n",
        "\t\t\t\t\tself.W += -self.alpha * error * x\n",
        "\n",
        "\tdef predict(self, X, addBias=True):\n",
        "\t\t# ensure our input is a matrix\n",
        "\t\tX = np.atleast_2d(X)\n",
        "\n",
        "\t\t# check to see if the bias column should be added\n",
        "\t\tif addBias:\n",
        "\t\t\t# insert a column of 1's as the last entry in the feature\n",
        "\t\t\t# matrix (bias)\n",
        "\t\t\tX = np.c_[X, np.ones((X.shape[0]))]\n",
        "\n",
        "\t\t# take the dot product between the input features and the\n",
        "\t\t# weight matrix, then pass the value through the step\n",
        "\t\t# function\n",
        "\t\treturn self.step(np.dot(X, self.W))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSjJfFw0S0LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimplePreprocessor:\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, and interpolation\n",
        "\t\t# method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# resize the image to a fixed size, ignoring the aspect\n",
        "\t\t# ratio\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),\n",
        "\t\t\tinterpolation=self.inter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eRrcBH_WTCWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "2afce429-0106-4fc3-e566-71d43ffbd753"
      },
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 55MB download may take a minute)\n",
        "print(\"[INFO] accessing MNIST...\")\n",
        "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
        "data = dataset.data\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] accessing MNIST...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6WPFTKpET8cZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if we are using \"channels first\" ordering, then reshape the\n",
        "# design matrix such that the matrix is:\n",
        "# num_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\tdata = data.reshape(data.shape[0], 1, 28, 28)\n",
        "# otherwise, we are using \"channels last\" ordering, so the design\n",
        "# matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\tdata = data.reshape(data.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H77hJfU_Updo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scale the input data to the range [0, 1] and perform a train/test\n",
        "# split\n",
        "(trainX, testX, trainY, testY) = train_test_split(data / 255.0,\n",
        "\tdataset.target.astype(\"int\"), test_size=0.25, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elqYergMUxuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the labels from integers to vectors\n",
        "le = LabelBinarizer()\n",
        "trainY = le.fit_transform(trainY)\n",
        "testY = le.transform(testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGC01TbcUz7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "1cf31cd9-400e-4063-c480-ba8f830072df"
      },
      "cell_type": "code",
      "source": [
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=0.01)\n",
        "model = LeNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsWTT10RU2qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "outputId": "3c9595d7-5b45-477d-d9a6-7cffc92aeed1"
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "\tbatch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.9551 - acc: 0.7375 - val_loss: 0.5945 - val_acc: 0.8087\n",
            "Epoch 2/20\n",
            "52500/52500 [==============================] - 128s 2ms/step - loss: 0.2742 - acc: 0.9182 - val_loss: 0.2836 - val_acc: 0.9034\n",
            "Epoch 3/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.1974 - acc: 0.9410 - val_loss: 0.1825 - val_acc: 0.9461\n",
            "Epoch 4/20\n",
            "52500/52500 [==============================] - 128s 2ms/step - loss: 0.1520 - acc: 0.9554 - val_loss: 0.1928 - val_acc: 0.9390\n",
            "Epoch 5/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.1252 - acc: 0.9630 - val_loss: 0.1141 - val_acc: 0.9673\n",
            "Epoch 6/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.1071 - acc: 0.9689 - val_loss: 0.1065 - val_acc: 0.9674\n",
            "Epoch 7/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.0941 - acc: 0.9718 - val_loss: 0.0947 - val_acc: 0.9721\n",
            "Epoch 8/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0851 - acc: 0.9742 - val_loss: 0.0938 - val_acc: 0.9717\n",
            "Epoch 9/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.0773 - acc: 0.9762 - val_loss: 0.0903 - val_acc: 0.9717\n",
            "Epoch 10/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.0706 - acc: 0.9781 - val_loss: 0.0795 - val_acc: 0.9763\n",
            "Epoch 11/20\n",
            "52500/52500 [==============================] - 128s 2ms/step - loss: 0.0658 - acc: 0.9795 - val_loss: 0.0964 - val_acc: 0.9706\n",
            "Epoch 12/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0609 - acc: 0.9812 - val_loss: 0.0657 - val_acc: 0.9803\n",
            "Epoch 13/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0574 - acc: 0.9822 - val_loss: 0.0638 - val_acc: 0.9815\n",
            "Epoch 14/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.0541 - acc: 0.9833 - val_loss: 0.0612 - val_acc: 0.9815\n",
            "Epoch 15/20\n",
            "52500/52500 [==============================] - 130s 2ms/step - loss: 0.0503 - acc: 0.9843 - val_loss: 0.0614 - val_acc: 0.9826\n",
            "Epoch 16/20\n",
            "52500/52500 [==============================] - 128s 2ms/step - loss: 0.0488 - acc: 0.9846 - val_loss: 0.0626 - val_acc: 0.9819\n",
            "Epoch 17/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0465 - acc: 0.9859 - val_loss: 0.3994 - val_acc: 0.8767\n",
            "Epoch 18/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0453 - acc: 0.9863 - val_loss: 0.0563 - val_acc: 0.9837\n",
            "Epoch 19/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0414 - acc: 0.9876 - val_loss: 0.0848 - val_acc: 0.9736\n",
            "Epoch 20/20\n",
            "52500/52500 [==============================] - 129s 2ms/step - loss: 0.0402 - acc: 0.9874 - val_loss: 0.0545 - val_acc: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "naPWNqo2eIVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "cc8adbf2-46c6-4fd8-efe1-26944e8eaa2d"
      },
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1),\n",
        "\ttarget_names=[str(x) for x in le.classes_]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1677\n",
            "           1       0.99      0.99      0.99      1935\n",
            "           2       0.98      0.99      0.99      1767\n",
            "           3       0.98      0.98      0.98      1766\n",
            "           4       0.98      0.99      0.99      1691\n",
            "           5       0.99      0.98      0.99      1653\n",
            "           6       0.99      0.99      0.99      1754\n",
            "           7       0.98      0.99      0.98      1846\n",
            "           8       0.97      0.98      0.97      1702\n",
            "           9       0.99      0.96      0.97      1709\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     17500\n",
            "   macro avg       0.98      0.98      0.98     17500\n",
            "weighted avg       0.98      0.98      0.98     17500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_sG2P8nkeNMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "aba913ad-3d28-48e6-828b-dc72aace61e2"
      },
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dvjupX22eQC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}